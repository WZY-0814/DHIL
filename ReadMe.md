# DHIL: Dual-channel Hierarchical Interactive Learning for Protein–Ligand Binding Affinity Prediction

## Overview

DHIL (Dual-channel Hierarchical Interactive Learning) is a novel deep learning approach for protein–ligand binding affinity (PLBA) prediction that addresses the limitations of conventional methods by explicitly modeling the hierarchical dependencies between intramolecular (covalent) and intermolecular (non-covalent) interactions. DHIL employs a dual-channel encoding framework that simultaneously captures detailed intramolecular interactions (using separate intra-type encoders for ligand and protein atom graphs) and spatial intermolecular interactions (via inter-type encoders operating on atom and substructure interaction graphs).
A key innovation of DHIL is its hierarchical interactive learning paradigm. At the atom level, the model uses local bridge nodes to enable bidirectional information exchange between the intra-type and inter-type channels, refining the atom-level representations through GRU-based updates and warp gate mechanisms. At the substructure level, global bridge nodes similarly facilitate the integration of ligand fragment and protein residue information, resulting in a comprehensive, multi-scale representation of the binding site. The final fused representation, obtained through pooling and further GRU processing, is used to predict the binding affinity accurately.

- Atom-level Encoding & Interactive Learning:
  This stage processes ligand and protein atom graphs (intra-type) to capture detailed chemical-bond information. An inter-type encoder then fuses these representations based on spatial interactions in the atom interaction graph. Finally, Atom-level Interactive Learning—using local bridge nodes, warp gate mechanisms, and GRU-based updates—facilitates bidirectional information exchange between the intra-type and inter-type channels.

- Substructure-level Encoding & Interactive Learning:
  At a higher level, the model processes ligand fragment and protein residue graphs. Initial substructure representations are formed by concatenating physical–chemical descriptors with aggregated atom-level outputs. Intra-type and inter-type encoders further update these representations using the substructure interaction graph, and Substructure-level Interactive Learning (via global bridge nodes) enhances these representations further.

  

## Dependencies

The DHIL model is implemented using the following key libraries:

- DGL (Deep Graph Library): version 1.0.2+cu116
- PyTorch: version 1.13.1+cu116
- RDKit: version 2022.9.5 (for handling molecular chemical structures)
- ProDy: version 2.4.0 (for protein structure analysis)
- torchani: version 2.2 (for additional molecular modeling functions)
- PyYAML: version 6.0  
- NumPy: version 1.23.5  


## Installation

1. Clone the Repository:

   git clone https://github.com/yourusername/DHIL.git
   cd DHIL

2. Set Up a Virtual Environment and Install Dependencies:

   python -m venv dhil_env
   source dhil_env/bin/activate  # On Windows: dhil_env\Scripts\activate
   pip install -r requirements.txt

   (Ensure that your CUDA version is compatible with the DGL and PyTorch versions specified.)



## Model Implementation Flow

1. Graph Construction & Feature Extraction:
   Raw protein–ligand complex data from the PDBbind dataset are processed using build_graph_dataset.py, along with featurize.py and graphs.py, to construct six types of graphs:
   - Intra-type graphs: Ligand Atom Graph & Protein Atom Graph, Ligand Fragment Graph & Protein Residue Graph.
   - Inter-type graphs: Atom Interaction Graph & Substructure Interaction Graph.

   These processed graph datasets are saved as refined_set_graphs.pkl and core_set_graphs.pkl.

2. Encoding & Interactive Learning:
   - Atom-level Encoding:
     Intra-type encoders process ligand and protein atom graphs to generate updated representations. An inter-type encoder then fuses these based on spatial interactions from the atom interaction graph. Atom-level Interactive Learning (using local bridge nodes, warp gate mechanisms, and GRU-based updates) further refines these representations.
   - Substructure-level Encoding:
     Initial substructure representations are generated by concatenating physical–chemical descriptors with aggregated atom-level outputs. Intra-type and inter-type encoders then update ligand fragment and protein residue graphs via the substructure interaction graph. Substructure-level Interactive Learning (using global bridge nodes) further enhances these representations.
   - Fusion & Prediction:
     The final ligand and protein substructure representations are pooled and fused. A GRU layer and a fully connected layer then map the fused representation to the predicted binding affinity.

3. Training & Evaluation:
   - Data Split:
     The refined-set is used as the training set (with 10% reserved for validation), and the core-set is used as the test set.
   - Loss & Optimization:
     The model is optimized using MSE loss with the Adam optimizer.
   - Early Stopping:
     Training stops early if the test set RMSE does not improve for 50 consecutive epochs.
   - Evaluation Metrics:
     Model performance is measured using RMSE, MAE, Pearson's correlation coefficient, and Standard Deviation (SD), as defined in Utils/metrics.py.

## How to Run

1. Data Preparation:
   Ensure that the raw datasets are properly placed under Data/PDBbind_dataset and that the INDEX_data.2016 file is available.

2. Graph Construction:
   Run the following command to generate graph data files (refined_set_graphs.pkl and core_set_graphs.pkl):

   python build_graph_dataset.py

3. Training:
   Execute the training script:

   python train.py

   The best model checkpoints will be saved in the Log/Models directory, and training logs will be stored in Log/train.log.


## Dataset

Due to file size constraints, only the refined-set and core-set from the PDBbind v2016 dataset are provided. Additional datasets are available via the references in the paper and are open source.

## Citation

If you use this code in your research, please cite the corresponding paper:

> [Dual-channel Hierarchical Interactive Learning for the Prediction of Protein-Ligand Binding Affinity]

## Contact

For further information, please contact: wzywzy202202@163.com
## License

This project is licensed under the MIT License.
